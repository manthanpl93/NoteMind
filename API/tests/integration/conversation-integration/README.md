

# Conversation Integration Tests

This document provides comprehensive documentation for all integration tests for the conversation management API.

## Test Configuration

**Environment Requirements:**
- `OPENAI_API_KEY_TEST` or `OPENAI_API_KEY` - Valid OpenAI API key for integration testing
- Tests use `gpt-4o-mini` model to minimize costs while testing
- Tests are marked with `@pytest.mark.integration` to be run separately from unit tests

**Running Tests:**
```bash
# Run all integration tests
pytest tests/integration/conversation-integration/ -v -m integration

# Run specific test class
pytest tests/integration/conversation-integration/test_conversation_integration.py::TestConversationCreation -v

# Run with coverage
pytest tests/integration/conversation-integration/ --cov=routes --cov=models --cov=utils -v -m integration
```

**Important Notes:**
- All tests make REAL API calls to OpenAI (no mocking)
- Tests require valid OpenAI API key in environment
- Tests will incur small API costs (using gpt-4o-mini for cost efficiency)
- Each test run creates and cleans up test data in MongoDB

---

## Test Class: TestConversationCreation

### 1. test_create_conversation_success

- **Purpose:** Verify creating a new conversation works end-to-end with real LLM integration
- **Input:** Valid provider (openai), model (gpt-4o-mini), first_message ("What is Python?")
- **Expected Outcome:** 
  - 201 Created status
  - Conversation saved to database with LLM-generated title
  - Response contains conversation_id, title, provider, model_name
  - Messages array contains the user message with timestamp and tokens_used
  - total_tokens_used field initialized and greater than 0

---

### 2. test_create_conversation_invalid_provider

- **Purpose:** Validate provider field accepts only valid values (openai, anthropic, google)
- **Input:** Provider="invalid_provider", model="some-model", first_message="Hello"
- **Expected Outcome:**
  - 422 Unprocessable Entity status
  - Error message indicating invalid provider value

---

### 3. test_create_conversation_no_api_key

- **Purpose:** Ensure user must have API key configured for the specified provider
- **Input:** Provider where user hasn't configured API key (e.g., anthropic)
- **Expected Outcome:**
  - 400 Bad Request status
  - Clear error message: "API key for {provider} is not configured. Please add your API key in settings."

---

### 4. test_create_conversation_title_generation

- **Purpose:** Verify LLM-powered title generation truncates and generates appropriate titles
- **Input:** First message with 100+ characters
- **Expected Outcome:**
  - 201 Created status
  - Title is generated by LLM (not simple truncation)
  - Title length is <= 60 characters
  - Title is descriptive and relevant to the message content
  - Original full message preserved in messages array

---

## Test Class: TestConversationListing

### 5. test_list_conversations_empty

- **Purpose:** Handle empty state gracefully when user has no conversations
- **Input:** New user with no conversations
- **Expected Outcome:**
  - 200 OK status
  - Empty array returned

---

### 6. test_list_conversations_sorted

- **Purpose:** Verify conversations are ordered by most recent activity (updated_at descending)
- **Input:** Create 3 conversations at different times
- **Expected Outcome:**
  - 200 OK status
  - Conversations sorted with most recently updated first
  - Each conversation has updated_at field
  - Chronological order maintained (newest first)

---

### 7. test_list_conversations_pagination

- **Purpose:** Test skip/limit pagination parameters work correctly
- **Input:** 15 conversations created, request with skip=5, limit=5
- **Expected Outcome:**
  - 200 OK status
  - Returns approximately 5 conversations (items 6-10)
  - Respects pagination parameters
  - Consistent ordering maintained

---

### 8. test_list_conversations_user_isolation

- **Purpose:** Critical security test - users cannot see other users' conversations
- **Input:** 
  - User A creates 3 conversations
  - User B creates 2 conversations
- **Expected Outcome:**
  - User A's GET request returns only their conversations
  - User B's GET request returns only their conversations
  - No data leakage between users
  - Each user sees different conversation counts and content

---

## Test Class: TestConversationRetrieval

### 9. test_get_conversation_success

- **Purpose:** Retrieve full conversation details including all messages and metadata
- **Input:** Valid conversation_id owned by authenticated user
- **Expected Outcome:**
  - 200 OK status
  - Complete conversation object with all required fields
  - Full messages array with all historical messages
  - Each message has role, content, timestamp, tokens_used
  - Timestamps and metadata included (created_at, updated_at)
  - total_tokens_used field present

---

### 10. test_get_conversation_not_found

- **Purpose:** Handle non-existent conversation gracefully
- **Input:** Random/invalid ObjectId that doesn't exist in database
- **Expected Outcome:**
  - 404 Not Found status
  - Clear error message

---

### 11. test_get_conversation_unauthorized

- **Purpose:** Prevent users from accessing other users' conversations
- **Input:** User B requests conversation owned by User A
- **Expected Outcome:**
  - 403 Forbidden or 404 Not Found status (to prevent information disclosure)
  - No conversation data returned
  - Security boundary enforced

---

## Test Class: TestConversationMessaging

### 12. test_send_message_success

- **Purpose:** Core functionality - send message and get AI response with real OpenAI call
- **Input:** 
  - Existing conversation_id
  - New user message: "What is 3+3? Answer with just the number."
  - Real OpenAI API call (gpt-4o-mini)
  - context_limit_tokens: 4000
- **Expected Outcome:**
  - 200 OK status
  - AI response returned in response body
  - Response contains "6" (validates real LLM call)
  - Both user message and AI response saved to database
  - Conversation messages array updated with both messages
  - Each message has timestamp and tokens_used
  - total_tokens_used incremented

---

### 13. test_send_message_context_limit

- **Purpose:** Verify token-based context window limiting works correctly
- **Input:**
  - Conversation with 20+ existing messages (mix of short and long messages)
  - New message with context_limit_tokens=500 (low limit to test truncation)
  - Real OpenAI API call (gpt-4o-mini)
- **Expected Outcome:**
  - 200 OK status
  - Only recent messages that fit within 500 token budget are sent to LLM
  - AI response returned successfully (validates it can still respond with limited context)
  - Full conversation history (all 20+ messages) preserved in database
  - No messages lost due to context limiting

---

### 14. test_send_message_updates_timestamp

- **Purpose:** Ensure updated_at timestamp reflects conversation activity for proper sorting
- **Input:** 
  - Existing conversation with known updated_at timestamp
  - Send new message
- **Expected Outcome:**
  - 200 OK status
  - updated_at is newer than original timestamp
  - Allows sorting by most recent activity in list view
  - Timestamp updated automatically

---

### 15. test_send_message_conversation_not_found

- **Purpose:** Handle invalid conversation_id gracefully
- **Input:** Non-existent conversation_id with valid message content
- **Expected Outcome:**
  - 404 Not Found status
  - Clear error message

---

### 16. test_send_message_unauthorized

- **Purpose:** Security - prevent sending messages to other users' conversations
- **Input:** User B attempts to send message to User A's conversation
- **Expected Outcome:**
  - 403 Forbidden status
  - No message saved to database
  - User A's conversation unchanged

---

## Test Class: TestConversationDeletion

### 17. test_delete_conversation_success

- **Purpose:** Verify conversation deletion works correctly
- **Input:** Valid conversation_id owned by authenticated user
- **Expected Outcome:**
  - 204 No Content status
  - Conversation removed from database
  - Subsequent GET request returns 404
  - Hard delete (not soft delete)

---

### 18. test_delete_conversation_unauthorized

- **Purpose:** Security - prevent deleting other users' conversations
- **Input:** User B attempts to delete User A's conversation
- **Expected Outcome:**
  - 403 Forbidden status
  - Conversation remains in database unchanged
  - User A can still access their conversation

---

## Test Class: TestConversationSecurity

### 19. test_conversation_preserves_provider_model

- **Purpose:** Ensure provider and model are stored correctly and remain immutable
- **Input:** Create conversation with provider=openai, model=gpt-4o-mini
- **Expected Outcome:**
  - Retrieved conversation has exact same provider and model
  - Values don't change after sending messages
  - Immutable after creation (provider/model locked to conversation)

---

### 20. test_multiple_providers_same_user

- **Purpose:** User can have concurrent conversations with different providers
- **Input:**
  - Create conversation with OpenAI (gpt-4o-mini)
  - Send message to OpenAI conversation
- **Expected Outcome:**
  - Conversations exist independently
  - Each uses correct provider's API key
  - Each maintains separate message history
  - No cross-contamination between conversations

---

## Test Class: TestTitleGeneration

### 21. test_title_generation_with_question

- **Purpose:** Test LLM-powered title generation with a question message
- **Input:** First message: "How do I learn Python programming from scratch?"
- **Expected Outcome:**
  - 201 Created status
  - Title generated by LLM is relevant to the content
  - Title length <= 60 characters
  - Title contains related keywords (python, learn, programming, etc.)
  - Title is descriptive and meaningful

---

### 22. test_title_generation_with_statement

- **Purpose:** Test LLM-powered title generation with a statement message
- **Input:** First message: "I need help understanding quantum computing and its applications."
- **Expected Outcome:**
  - 201 Created status
  - Title generated appropriately for statement-style messages
  - Title length <= 60 characters
  - Title is descriptive

---

### 23. test_title_generation_fallback

- **Purpose:** Test title generation has fallback for edge cases (very short messages)
- **Input:** Very short first message: "Hi"
- **Expected Outcome:**
  - 201 Created status
  - Title still generated (fallback to truncation if LLM fails)
  - Title is not empty
  - System handles edge case gracefully

---

## Test Class: TestTokenTracking

### 24. test_token_tracking_on_creation

- **Purpose:** Test tokens are tracked when creating a conversation
- **Input:** Create conversation with first message: "This is a test message for token tracking."
- **Expected Outcome:**
  - 201 Created status
  - total_tokens_used field exists and > 0
  - First message has tokens_used field > 0
  - Token counting uses tiktoken library
  - Accurate token count for the message

---

### 25. test_token_accumulation

- **Purpose:** Test tokens accumulate correctly across conversation lifecycle
- **Input:**
  - Create conversation (track initial tokens)
  - Send follow-up message
  - Get updated conversation
- **Expected Outcome:**
  - total_tokens_used increases with each message
  - New total > initial total
  - Accumulation is additive (sum of all message tokens)
  - No token count loss

---

### 26. test_token_tracking_per_message

- **Purpose:** Test each message tracks its own token usage independently
- **Input:**
  - Create conversation with multiple messages
  - Retrieve full conversation
- **Expected Outcome:**
  - Every message has tokens_used field
  - Each message's tokens_used > 0
  - Individual message token counts are accurate
  - Can audit token usage per message

---

## Test Fixtures

### authenticated_client
- **Purpose:** HTTP client with JWT authentication token
- **Setup:** Creates test user with OpenAI API key, generates JWT token
- **Usage:** Used in all tests requiring authenticated requests

### second_authenticated_client
- **Purpose:** Second authenticated client for testing user isolation
- **Setup:** Creates second test user with separate API key
- **Usage:** Used in security and isolation tests

### user_with_openai_key
- **Purpose:** Test user with OpenAI API key configured
- **Setup:** Creates user document with encrypted OpenAI API key from environment
- **Usage:** Used as the authenticated user for most tests

### second_user_with_openai_key
- **Purpose:** Second test user for isolation testing
- **Setup:** Creates second user document with encrypted OpenAI API key
- **Usage:** Used to verify users cannot access each other's data

### sample_conversation
- **Purpose:** Pre-created conversation for testing retrieval and updates
- **Setup:** Creates conversation with 2 messages and token tracking
- **Usage:** Used in tests that need existing conversation data

### test_db
- **Purpose:** Test MongoDB database connection
- **Setup:** Connects to test database, cleans up after tests
- **Usage:** Used to verify database state and perform direct queries

---

## Summary

**Total Tests:** 26 integration tests across 8 test classes

**Coverage:**
- Conversation CRUD operations (Create, Read, Update, Delete)
- Real LLM integration with OpenAI (no mocking)
- Token-based context window limiting
- LLM-powered title generation
- Token usage tracking and accumulation
- User authentication and authorization
- Data isolation between users
- Error handling and edge cases
- Security boundaries

**Test Approach:**
- Test-Driven Development (TDD) - tests written before implementation
- Real API calls for end-to-end validation
- Comprehensive security testing
- Performance-conscious (uses gpt-4o-mini for cost efficiency)


